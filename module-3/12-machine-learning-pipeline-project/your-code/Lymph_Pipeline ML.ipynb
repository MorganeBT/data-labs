{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "amount of entries is 2812\n",
      "dimensions= 2\n",
      "shape is (148, 19)\n",
      "axes: [RangeIndex(start=0, stop=148, step=1), Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], dtype='int64')]\n",
      "data types of columns:\n",
      "0     int64\n",
      "1     int64\n",
      "2     int64\n",
      "3     int64\n",
      "4     int64\n",
      "5     int64\n",
      "6     int64\n",
      "7     int64\n",
      "8     int64\n",
      "9     int64\n",
      "10    int64\n",
      "11    int64\n",
      "12    int64\n",
      "13    int64\n",
      "14    int64\n",
      "15    int64\n",
      "16    int64\n",
      "17    int64\n",
      "18    int64\n",
      "dtype: object\n",
      "features: Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], dtype='int64')\n",
      "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18\n",
      "0   3   4   2   1   1   1   1   1   2   1   2   2   2   4   8   1   1   2   2\n",
      "1   2   3   2   1   1   2   2   1   2   1   3   3   2   3   4   2   2   2   2\n",
      "2   3   3   2   2   2   2   2   2   2   1   4   3   3   4   8   3   2   2   7\n",
      "3   3   3   1   1   1   1   2   1   2   1   3   3   4   4   4   3   1   2   6\n",
      "4   2   3   1   1   1   1   1   1   1   1   2   2   4   3   5   1   2   2   1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "amount of entries is 2556\n",
      "dimensions= 2\n",
      "shape is (142, 18)\n",
      "axes: [Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
      "            ...\n",
      "            137, 138, 140, 141, 142, 143, 144, 145, 146, 147],\n",
      "           dtype='int64', length=142), Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], dtype='int64')]\n",
      "data types of columns:\n",
      "1     int64\n",
      "2     int64\n",
      "3     int64\n",
      "4     int64\n",
      "5     int64\n",
      "6     int64\n",
      "7     int64\n",
      "8     int64\n",
      "9     int64\n",
      "10    int64\n",
      "11    int64\n",
      "12    int64\n",
      "13    int64\n",
      "14    int64\n",
      "15    int64\n",
      "16    int64\n",
      "17    int64\n",
      "18    int64\n",
      "dtype: object\n",
      "features: Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], dtype='int64')\n",
      "   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18\n",
      "0   4   2   1   1   1   1   1   2   1   2   2   2   4   8   1   1   2   2\n",
      "1   3   2   1   1   2   2   1   2   1   3   3   2   3   4   2   2   2   2\n",
      "2   3   2   2   2   2   2   2   2   1   4   3   3   4   8   3   2   2   7\n",
      "3   3   1   1   1   1   2   1   2   1   3   3   4   4   4   3   1   2   6\n",
      "4   3   1   1   1   1   1   1   1   1   2   2   4   3   5   1   2   2   1\n",
      "\n",
      "0    3\n",
      "1    2\n",
      "2    3\n",
      "3    3\n",
      "4    2\n",
      "Name: 0, dtype: int64\n",
      "Mean CV accuracy= 0.767619\n",
      "[6 2 7 2 5 7 6 6 4 3 3 5 6 2 3 3 0 1]\n",
      "class label is 2\n",
      "--- end of execution ---\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn import datasets, utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas.io\n",
    "from sklearn import tree, pipeline, preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "#\n",
    "# DECLARATION PART\n",
    "#\n",
    "PIPELINEPATH= \"ser_pipeline.pickle\"\n",
    "DATASETPATH= \"lymphography.data\"\n",
    "\n",
    "\n",
    "\n",
    "# if there is no header row with the column/attribute names, use the constant None for row_with_column_names\n",
    "def readCsvToDataFrame(path, row_with_column_names):\n",
    "    theDataFrame= pandas.read_csv(path, header=row_with_column_names)\n",
    "    return theDataFrame\n",
    "\n",
    "\n",
    "\n",
    "def show_df_info(dataframe):\n",
    "    # get the data type\n",
    "    print(type(dataframe))\n",
    "    print(\"amount of entries is %s\" % dataframe.size)\n",
    "    print(\"dimensions= %i\" % dataframe.ndim)\n",
    "    print(\"shape is \", end=\"\")\n",
    "    print(dataframe.shape)\n",
    "    print(\"axes: \", end=\"\")\n",
    "    print(dataframe.axes)\n",
    "    print(\"data types of columns:\")\n",
    "    print(dataframe.dtypes)\n",
    "    print(\"features: %s\" % dataframe.columns)\n",
    "\n",
    "\n",
    "\n",
    "def sliceDataFrame(df):\n",
    "    # remove 2 instances with class label \"normal find\"\n",
    "    df= df.drop(df[df[0]==1].index)\n",
    "    # remove 4 instances with class label \"fibrosis\"\n",
    "    df = df.drop(df[df[0] == 4].index)\n",
    "    # iloc arguments: range of rows, range of columns\n",
    "    # class 'pandas.core.series.Series'\n",
    "    return df.iloc[:, 1:], df.iloc[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# PROGRAM BODY\n",
    "#\n",
    "\n",
    "## PHASE 1: LOAD DATASET\n",
    "dataset= readCsvToDataFrame(DATASETPATH, None)\n",
    "show_df_info(dataset)\n",
    "print(dataset.head(5))\n",
    "\n",
    "## PHASE 2: SLICE DATASET\n",
    "training_instances, class_labels= sliceDataFrame(dataset)\n",
    "show_df_info(training_instances)\n",
    "# preview the data\n",
    "print(training_instances.head(5))\n",
    "print()\n",
    "print(class_labels.head(5))\n",
    "\n",
    "## PHASE 3: CREATE PIPELINE\n",
    "cart_model= tree.DecisionTreeClassifier()\n",
    "pipe= pipeline.Pipeline(steps=[(\"feature_selection\", SelectKBest(chi2, k=8)), (\"scale\", preprocessing.StandardScaler()),  (\"CART\", cart_model)])\n",
    "\n",
    "## PHASE 4: TRAIN\n",
    "# fit all stages of the pipeline\n",
    "pipe.fit(training_instances, y=class_labels)\n",
    "\n",
    "## PHASE 5: EVALUATE\n",
    "# return value is array of scores\n",
    "scores = cross_val_score(pipe, training_instances, class_labels, cv=5)\n",
    "# use as quality metric the average CV score\n",
    "meanCvAccuracy= scores.mean()\n",
    "print(\"Mean CV accuracy= %f\" % meanCvAccuracy)\n",
    "\n",
    "## PHASE 6: SAVE PIPELINE\n",
    "# the whole pipeline in one single file\n",
    "joblib.dump(pipe, PIPELINEPATH, compress = 1)\n",
    "\n",
    "## PHASE 7: LOAD THE PIPELINE\n",
    "# read the file and deserialize the pipeline\n",
    "pipeline_loaded = joblib.load(PIPELINEPATH)\n",
    "\n",
    "## PHASE 8: CLASSIFY NEW INSTANCES\n",
    "# create new random problem instance\n",
    "vector= numpy.random.randint(0, 8, size=18)\n",
    "print(vector)\n",
    "result= pipeline_loaded.predict([vector,])\n",
    "print(\"class label is %i\" % result)\n",
    "\n",
    "print(\"--- end of execution ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
